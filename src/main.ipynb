{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TODO\n",
    "* copy in other file\n",
    "* find unused code\n",
    "* doublecheck zeropoints\n",
    "* doublecheck catalogue\n",
    "* check folder - a temp data folder\n",
    "* catalogue referencing later is not with variablized\n",
    "* update planck cosmology"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "catalogue = \"gds/jades/phot/hlsp_jades_jwst_nircam_goods-s-deep_photometry_v1.0_catalog_large_withSpec.fits\"\n",
    "cat_out_name = \"gds_jwst_nircam_large_withSpec\"\n",
    "templates = [\n",
    "    \"EMlines\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "import eazy, os\n",
    "\n",
    "import matplotlib as mpl\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import time\n",
    "from math import ceil, floor\n",
    "from copy import deepcopy as copy\n",
    "\n",
    "from astropy import units as u\n",
    "from astropy.cosmology import Planck18\n",
    "from astropy.io import fits\n",
    "from astropy.table import Table, join, hstack\n",
    "from astropy.visualization import ZScaleInterval as zs\n",
    "from astroquery.mast import Observations as obs\n",
    "from IPython.utils import io\n",
    "from matplotlib.transforms import Affine2D\n",
    "from mpl_toolkits.axes_grid1.inset_locator import inset_axes\n",
    "\n",
    "import eazy_routines as ez\n",
    "import helper_module as hmod\n",
    "\n",
    "if not os.path.exists('templates'):\n",
    "    eazy.symlink_eazy_inputs()\n",
    "\n",
    "cosmo = Planck18\n",
    "\n",
    "if \"temp\" not in os.listdir():\n",
    "    os.mkdir(\"temp\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log all camera filters\n",
    "flt = eazy.filters.FilterFile()\n",
    "\n",
    "filts_nircam = {\n",
    "        'F090W': 363,\n",
    "        'F115W': 364,\n",
    "        'F150W': 365,\n",
    "        'F182M': 370,\n",
    "        'F200W': 366,\n",
    "        'F210M': 371,\n",
    "        'F277W': 375,\n",
    "        'F335M': 381,\n",
    "        'F356W': 376,\n",
    "        'F410M': 383,\n",
    "        'F430M': 384,\n",
    "        'F444W': 358,\n",
    "        'F460M': 385,\n",
    "        'F480M': 386\n",
    "}\n",
    "\n",
    "filts_HST = {\n",
    "        'F105W': 202,\n",
    "        'F125W': 203,\n",
    "        'F140W': 204,\n",
    "        'F160W': 205,\n",
    "        'F435W': 233,\n",
    "        'F606W': 214,\n",
    "        'F775W': 216,\n",
    "        'F814W': 239,\n",
    "        'F850LP': 240\n",
    "}\n",
    "\n",
    "filts = {**filts_nircam, **filts_HST}\n",
    "\n",
    "mw_reddening = ez.get_atten_dict(filts)#!is used?\n",
    "\n",
    "# get zeropoints\n",
    "zps = [1.0]*len(filts)#!should be evaluated if this is correct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filename: /home/tb/astrodata/gds/jades/phot/hlsp_jades_jwst_nircam_goods-s-deep_photometry_v1.0_catalog_large_withSpec.fits\n",
      "No.    Name      Ver    Type      Cards   Dimensions   Format\n",
      "  0  PRIMARY       1 PrimaryHDU      13   ()      \n",
      "  1  FILTERS       1 BinTableHDU     33   23R x 12C   [6A, E, E, E, E, E, E, E, E, E, E, E]   \n",
      "  2  FLAG          1 BinTableHDU    161   1429R x 75C   [J, D, D, J, J, J, J, J, J, J, J, J, J, J, J, J, J, J, J, J, J, J, J, J, J, J, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, I, E, E]   \n",
      "  3  SIZE          1 BinTableHDU    100   1429R x 43C   [J, D, D, E, D, D, D, D, J, J, J, J, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E]   \n",
      "  4  CIRC          1 BinTableHDU    856   1429R x 423C   [J, D, D, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E]   \n",
      "  5  CIRC_BSUB     1 BinTableHDU    856   1429R x 423C   [J, D, D, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E]   \n",
      "  6  CIRC_CONV     1 BinTableHDU    856   1429R x 423C   [J, D, D, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E]   \n",
      "  7  KRON          1 BinTableHDU    376   1429R x 183C   [J, D, D, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E]   \n",
      "  8  KRON_CONV     1 BinTableHDU    376   1429R x 183C   [J, D, D, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E, E]   \n",
      "  9  PHOTOZ        1 BinTableHDU     42   1429R x 16C   [J, D, D, D, D, D, D, D, D, D, D, D, D, 20A, 20A, 100A]   \n",
      "None\n"
     ]
    }
   ],
   "source": [
    "#=== load data\n",
    "#inname = \"hlsp_jades_jwst_nircam_goods-s-deep_photometry_v1.0_catalog.fits\"\n",
    "inname = catalogue.split('/')[-1]\n",
    "inpath = os.path.join(os.getenv('astrodata'), catalogue)\n",
    "\n",
    "# print the meta info\n",
    "with fits.open(inpath) as hdul:\n",
    "    print(hdul.info())\n",
    "\n",
    "# load photometry table\n",
    "tab = Table.read(inpath, hdu=6)\n",
    "tab_redshifts = Table.read(inpath, hdu=9)\n",
    "\n",
    "#=== make EAZY table\n",
    "\n",
    "# load fluxes\n",
    "# CIRC1: 0.10 arcsec aperture (see README)\n",
    "ext = '_CIRC1'\n",
    "cols_dummy = hmod.get_matches(ext, tab.columns, exclude='_ei')\n",
    "cols_f = np.sort(hmod.get_matches(ext, cols_dummy, exclude='_e'))\n",
    "cols_fe = np.sort(hmod.get_matches('_e', cols_dummy))\n",
    "cols_fluxes = list(np.vstack([cols_f, cols_fe]).T.flatten())\n",
    "cols = list(np.insert(cols_fluxes, 0, ['ID', 'RA', 'DEC', 'z_spec']))\n",
    "del cols_dummy\n",
    "\n",
    "tab = join(tab, tab_redshifts['ID', 'z_spec'], join_type='inner', keys='ID')\n",
    "tab_out = tab[cols]\n",
    "\n",
    "# convert from nJy to uJy\n",
    "# and apply MW reddening\n",
    "keys = np.array(list(mw_reddening.keys()))\n",
    "for c in cols_fluxes:\n",
    "    tab_out[c].unit = u.nJy\n",
    "    tab_out[c] = tab_out[c].to(u.uJy)\n",
    "    \n",
    "    # apply MW reddening\n",
    "    matches = hmod.get_matches(keys, c, get_idxs=True)\n",
    "    key = keys[np.int32(matches[:,0])][0]\n",
    "    tab_out[c] *= mw_reddening[key]\n",
    "del c, keys, key, matches\n",
    "    \n",
    "# rename columns\n",
    "for c in cols_f:\n",
    "    cnew = c.replace(ext, '_flux')\n",
    "    tab_out.rename_column(c, cnew)\n",
    "del c, cnew\n",
    "\n",
    "for c in cols_fe:\n",
    "    cnew = c.replace(ext+'_e', '_err')\n",
    "    tab_out.rename_column(c, cnew)\n",
    "del c, cnew\n",
    "\n",
    "#=== apply MW reddening\n",
    "#atten_dict = ez.get_atten_dict(filts_eazyres, filts_str)\n",
    "#degr_image_sig *= atten_dict[filt] / 100. # uJy\n",
    "\n",
    "# save EAZY table\n",
    "tab_out.write('temp/eazy_input.fits', format='fits', overwrite=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "runTime = int(time.time())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=== set up paths for eazy\n",
    "\n",
    "# catalog paths\n",
    "cat_path = 'temp/eazy_input.fits'\n",
    "keys_id = ['ID id', 'RA ra', 'DEC dec', 'z_spec z_spec']\n",
    "\n",
    "# template names and paths\n",
    "ftempl_strs = [\n",
    "    'EMextreme',\n",
    "    'EMlines',\n",
    "    'fsps_45k_0.3removed',\n",
    "    'fsps_45k',\n",
    "    'fsps_60k',\n",
    "    'carnall_sfhz_13',\n",
    "    'corr_sfhz_13',\n",
    "    'blue_sfhz_13',\n",
    "    'eazy_v1.1_lines.spectra', \n",
    "    'eazy_v1.3.spectra',\n",
    "    'br07_default.spectra',\n",
    "    #'pegase.spectra',\n",
    "    'pegase13.spectra',\n",
    "    #'cww+kin.spectra'\n",
    "    ]\n",
    "templ_paths = [f\"templates/{e}.param\" for e in ftempl_strs]\n",
    "out_names = [f for f in ftempl_strs]#!there is better syntax for editting strings like this\n",
    "out_paths = [f\"eazy-output/{f}_{runTime}\" for f in out_names]\n",
    "#paths = np.array([templ_paths, out_paths]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Read default param file: /home/tb/miniconda3/envs/eazy39/lib/python3.9/site-packages/eazy/data/zphot.param.default\n",
      "Read CATALOG_FILE: temp/eazy_input.fits\n",
      "   >>> NOBJ = 1429\n",
      "F090W_flux F090W_err (363): jwst_nircam_f090w\n",
      "F115W_flux F115W_err (364): jwst_nircam_f115w\n",
      "F150W_flux F150W_err (365): jwst_nircam_f150w\n",
      "F182M_flux F182M_err (370): jwst_nircam_f182m\n",
      "F200W_flux F200W_err (366): jwst_nircam_f200w\n",
      "F210M_flux F210M_err (371): jwst_nircam_f210m\n",
      "F277W_flux F277W_err (375): jwst_nircam_f277w\n",
      "F335M_flux F335M_err (381): jwst_nircam_f335m\n",
      "F356W_flux F356W_err (376): jwst_nircam_f356w\n",
      "F410M_flux F410M_err (383): jwst_nircam_f410m\n",
      "F430M_flux F430M_err (384): jwst_nircam_f430m\n",
      "F444W_flux F444W_err (358): jwst_niriss_f444w\n",
      "F460M_flux F460M_err (385): jwst_nircam_f460m\n",
      "F480M_flux F480M_err (386): jwst_nircam_f480m\n",
      "F105W_flux F105W_err (202): hst/wfc3/IR/f105w.dat\n",
      "F125W_flux F125W_err (203): hst/wfc3/IR/f125w.dat\n",
      "F140W_flux F140W_err (204): hst/wfc3/IR/f140w.dat\n",
      "F160W_flux F160W_err (205): hst/wfc3/IR/f160w.dat\n",
      "F435W_flux F435W_err (233): hst/ACS_update_sep07/wfc_f435w_t81.dat\n",
      "F606W_flux F606W_err (214): hst/wfc3/UVIS/f606w.dat\n",
      "F775W_flux F775W_err (216): hst/wfc3/UVIS/f775w.dat\n",
      "F814W_flux F814W_err (239): hst/ACS_update_sep07/wfc_f814w_t81.dat\n",
      "F850LP_flux F850LP_err (240): hst/ACS_update_sep07/wfc_f850lp_t81.dat\n",
      "Set sys_err = 0.01 (positive=True)\n",
      "Read PRIOR_FILE:  templates/prior_F160W_TAO.dat\n",
      "Template grid: templates/EMextreme.param (this may take some time)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tb/miniconda3/envs/eazy39/lib/python3.9/site-packages/eazy/photoz.py:1326: RuntimeWarning: invalid value encountered in log10\n",
      "  self.prior_mag_cat += -2.5*np.log10(np.squeeze(self.fnu[:,ix]))\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/mnt/c/Users/thorb/git/EAZY_templates_comparrison_pipeline/src/main.ipynb Cell 8\u001b[0m line \u001b[0;36m2\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/thorb/git/EAZY_templates_comparrison_pipeline/src/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39m# run eazy\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/thorb/git/EAZY_templates_comparrison_pipeline/src/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=19'>20</a>\u001b[0m \u001b[39m#idx = np.array([0])\u001b[39;00m\n\u001b[1;32m     <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/thorb/git/EAZY_templates_comparrison_pipeline/src/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=20'>21</a>\u001b[0m idx \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m---> <a href='vscode-notebook-cell://wsl%2Bubuntu/mnt/c/Users/thorb/git/EAZY_templates_comparrison_pipeline/src/main.ipynb#X10sdnNjb2RlLXJlbW90ZQ%3D%3D?line=21'>22</a>\u001b[0m zout, hdu \u001b[39m=\u001b[39m ez\u001b[39m.\u001b[39;49mrun_eazy(params, fnames, n_proc\u001b[39m=\u001b[39;49m\u001b[39m-\u001b[39;49m\u001b[39m1\u001b[39;49m, idx\u001b[39m=\u001b[39;49midx)\n",
      "File \u001b[0;32m/mnt/c/Users/thorb/git/EAZY_templates_comparrison_pipeline/src/eazy_routines.py:130\u001b[0m, in \u001b[0;36mrun_eazy\u001b[0;34m(params, fnames_cfg, n_proc, idx)\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mrun_eazy\u001b[39m(params, fnames_cfg, n_proc\u001b[39m=\u001b[39m\u001b[39m-\u001b[39m\u001b[39m1\u001b[39m, idx\u001b[39m=\u001b[39m\u001b[39mNone\u001b[39;00m):\n\u001b[1;32m    128\u001b[0m     \n\u001b[1;32m    129\u001b[0m     \u001b[39m#=== fit the catalog & save output\u001b[39;00m\n\u001b[0;32m--> 130\u001b[0m     pz \u001b[39m=\u001b[39m eazy_init_photoz(params, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mfnames_cfg) \u001b[39m# get a photoz object\u001b[39;00m\n\u001b[1;32m    132\u001b[0m     \u001b[39m# fix z_spec\u001b[39;00m\n\u001b[1;32m    133\u001b[0m     pz\u001b[39m.\u001b[39mfit_catalog(idx\u001b[39m=\u001b[39midx, n_proc\u001b[39m=\u001b[39mn_proc)\n",
      "File \u001b[0;32m/mnt/c/Users/thorb/git/EAZY_templates_comparrison_pipeline/src/eazy_routines.py:91\u001b[0m, in \u001b[0;36meazy_init_photoz\u001b[0;34m(params, fparam, ftran, fzp, kwargs)\u001b[0m\n\u001b[1;32m     85\u001b[0m \u001b[39m# photoz config\u001b[39;00m\n\u001b[1;32m     86\u001b[0m kwargs \u001b[39m=\u001b[39m \u001b[39mdict\u001b[39m(param_file\u001b[39m=\u001b[39mfparam, \n\u001b[1;32m     87\u001b[0m               translate_file\u001b[39m=\u001b[39mftran, \n\u001b[1;32m     88\u001b[0m               zeropoint_file\u001b[39m=\u001b[39mfzp, \n\u001b[1;32m     89\u001b[0m               params\u001b[39m=\u001b[39mparams,\n\u001b[1;32m     90\u001b[0m               \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwargs)\n\u001b[0;32m---> 91\u001b[0m pz \u001b[39m=\u001b[39m eazy\u001b[39m.\u001b[39;49mphotoz\u001b[39m.\u001b[39;49mPhotoZ(\u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m     92\u001b[0m \u001b[39mreturn\u001b[39;00m pz\n",
      "File \u001b[0;32m~/miniconda3/envs/eazy39/lib/python3.9/site-packages/eazy/photoz.py:348\u001b[0m, in \u001b[0;36mPhotoZ.__init__\u001b[0;34m(self, param_file, translate_file, zeropoint_file, load_prior, load_products, params, n_proc, cosmology, compute_tef_lnp, tempfilt, tempfilt_data, random_seed, random_draws, **kwargs)\u001b[0m\n\u001b[1;32m    345\u001b[0m \u001b[39mprint\u001b[39m(msg\u001b[39m.\u001b[39mformat(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mparam[\u001b[39m'\u001b[39m\u001b[39mTEMPLATES_FILE\u001b[39m\u001b[39m'\u001b[39m]))\n\u001b[1;32m    347\u001b[0m t0 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[0;32m--> 348\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mtempfilt \u001b[39m=\u001b[39m TemplateGrid(\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mzgrid, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtemplates, \n\u001b[1;32m    349\u001b[0m                             RES\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam[\u001b[39m'\u001b[39;49m\u001b[39mFILTERS_RES\u001b[39;49m\u001b[39m'\u001b[39;49m], \n\u001b[1;32m    350\u001b[0m                             f_numbers\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mf_numbers, \n\u001b[1;32m    351\u001b[0m                             add_igm\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam[\u001b[39m'\u001b[39;49m\u001b[39mIGM_SCALE_TAU\u001b[39;49m\u001b[39m'\u001b[39;49m], \n\u001b[1;32m    352\u001b[0m                         galactic_ebv\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mMW_EBV, \n\u001b[1;32m    353\u001b[0m                         Eb\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mparam[\u001b[39m'\u001b[39;49m\u001b[39mSCALE_2175_BUMP\u001b[39;49m\u001b[39m'\u001b[39;49m], \n\u001b[1;32m    354\u001b[0m                         n_proc\u001b[39m=\u001b[39;49mn_proc, cosmology\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mcosmology, \n\u001b[1;32m    355\u001b[0m                         array_dtype\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mARRAY_DTYPE, \n\u001b[1;32m    356\u001b[0m                         tempfilt_data\u001b[39m=\u001b[39;49mtempfilt_data)\n\u001b[1;32m    357\u001b[0m t1 \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mtime()\n\u001b[1;32m    358\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m'\u001b[39m\u001b[39mProcess templates: \u001b[39m\u001b[39m{0:.3f}\u001b[39;00m\u001b[39m s\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.\u001b[39mformat(t1\u001b[39m-\u001b[39mt0))\n",
      "File \u001b[0;32m~/miniconda3/envs/eazy39/lib/python3.9/site-packages/eazy/photoz.py:5417\u001b[0m, in \u001b[0;36mTemplateGrid.__init__\u001b[0;34m(self, zgrid, templates, RES, f_numbers, add_igm, galactic_ebv, Eb, n_proc, interpolator, filters, verbose, cosmology, array_dtype, tempfilt_data)\u001b[0m\n\u001b[1;32m   5414\u001b[0m             all_filters \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mload(RES\u001b[39m+\u001b[39m\u001b[39m'\u001b[39m\u001b[39m.npy\u001b[39m\u001b[39m'\u001b[39m, \n\u001b[1;32m   5415\u001b[0m                                   allow_pickle\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)[\u001b[39m0\u001b[39m]\n\u001b[1;32m   5416\u001b[0m         \u001b[39melse\u001b[39;00m:\n\u001b[0;32m-> 5417\u001b[0m             all_filters \u001b[39m=\u001b[39m filters_code\u001b[39m.\u001b[39;49mFilterFile(RES)\n\u001b[1;32m   5419\u001b[0m     filters \u001b[39m=\u001b[39m [all_filters[fnum] \u001b[39mfor\u001b[39;00m fnum \u001b[39min\u001b[39;00m f_numbers]\n\u001b[1;32m   5421\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mfilter_names \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([f\u001b[39m.\u001b[39mname \u001b[39mfor\u001b[39;00m f \u001b[39min\u001b[39;00m filters])\n",
      "File \u001b[0;32m~/miniconda3/envs/eazy39/lib/python3.9/site-packages/eazy/filters.py:308\u001b[0m, in \u001b[0;36mFilterFile.__init__\u001b[0;34m(self, file, path)\u001b[0m\n\u001b[1;32m    306\u001b[0m         lspl \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mcast[\u001b[39mfloat\u001b[39m](line\u001b[39m.\u001b[39msplit())\n\u001b[1;32m    307\u001b[0m         wave\u001b[39m.\u001b[39mappend(lspl[\u001b[39m1\u001b[39m])\n\u001b[0;32m--> 308\u001b[0m         trans\u001b[39m.\u001b[39mappend(lspl[\u001b[39m2\u001b[39;49m])\n\u001b[1;32m    310\u001b[0m \u001b[39m# last one\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[39m# new_filter = FilterDefinition()\u001b[39;00m\n\u001b[1;32m    312\u001b[0m \u001b[39m# new_filter.name = header\u001b[39;00m\n\u001b[1;32m    313\u001b[0m \u001b[39m# new_filter.wave = np.cast[float](wave)\u001b[39;00m\n\u001b[1;32m    314\u001b[0m \u001b[39m# new_filter.throughput = np.cast[float](trans)\u001b[39;00m\n\u001b[1;32m    315\u001b[0m new_filter \u001b[39m=\u001b[39m FilterDefinition(name\u001b[39m=\u001b[39mheader,\n\u001b[1;32m    316\u001b[0m                               wave\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mcast[\u001b[39mfloat\u001b[39m](wave), \n\u001b[1;32m    317\u001b[0m                         throughput\u001b[39m=\u001b[39mnp\u001b[39m.\u001b[39mcast[\u001b[39mfloat\u001b[39m](trans))\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# iterate over tempalte sets\n",
    "for tpath, opath, oname in zip(templ_paths, out_paths, out_names):\n",
    "    \n",
    "    params = {\"cat_path\": cat_path,\n",
    "              \"templ_path\": tpath,\n",
    "              \"out_path\": opath,\n",
    "              \"FIX_ZSPEC\": 'n',\n",
    "              \"USE_ZSPEC_FOR_REST\": 'n',\n",
    "              \"Z_MAX\": 12.0,\n",
    "              \"H0\": cosmo.H0,\n",
    "              \"OMEGA_M\": cosmo.Om0,\n",
    "              \"OMEGA_L\": cosmo.Ode0,\n",
    "              \"CATALOG_FORMAT\": 'fits'}\n",
    "    \n",
    "    # write eazy config files\n",
    "    filt_num, fnames = ez.write_config(f'{cat_out_name}_{oname}', filts, zps, keys_id,\n",
    "                                       out_path=opath)\n",
    "\n",
    "    # run eazy\n",
    "    #idx = np.array([0])\n",
    "    idx = None\n",
    "    zout, hdu = ez.run_eazy(params, fnames, n_proc=-1, idx=idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#find latest runTime in folder:\n",
    "runTime = int(np.sort([int(f.split('_')[-1]) for f in os.listdir('eazy-output')])[-1])\n",
    "outpaths = 'eazy-output/{ftempl}_{runTime}/gds_jades_eazy.zout.fits'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=== load EAZY outputs\n",
    "fpath = 'eazy-output/{ftempl}_{runTime}/gds_jades_eazy.zout.fits'\n",
    "ftempl = ftempl_strs[0]\n",
    "fpath = fpath.format(ftempl=ftempl, runTime=runTime)\n",
    "tbl = Table.read(fpath)\n",
    "names = [name for name in tbl.colnames if len(tbl[name].shape) <= 1]\n",
    "df = tbl[names].to_pandas()\n",
    "#change df 'id' to 'ID'\n",
    "df.rename(columns={'id': 'ID'}, inplace=True)\n",
    "\n",
    "fname = \"hlsp_jades_jwst_nircam_goods-s-deep_photometry_v1.0_catalog.fits\"\n",
    "fpath = os.path.join(os.getenv('astrodata'), 'gds/jades/phot', fname)\n",
    "tbl = Table.read(fpath, hdu=9)\n",
    "names = [name for name in tbl.colnames if len(tbl[name].shape) <= 1]\n",
    "names = [name for name in names if \n",
    "    'ID' in name or\n",
    "    'EAZY_z_a' in name or \n",
    "    'z_spec_source' in name or \n",
    "    'z_spec_quality' in name or\n",
    "    'z_spec_reference' in name\n",
    "]\n",
    "df_spec = tbl[names].to_pandas()\n",
    "\n",
    "# add spec info to the photo table\n",
    "df = pd.merge(df, df_spec, on='ID', how='left')\n",
    "\n",
    "#=== create masks\n",
    "masks = {}\n",
    "masks['z_spec'] = ~df['z_spec'].isna()\n",
    "\n",
    "for i, (k, m) in enumerate(masks.items()):\n",
    "    if isinstance(m, pd.Series):\n",
    "        masks[k] = m.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mask_cur = masks['z_spec']\n",
    "\n",
    "x = df['z_spec'].values[mask_cur]\n",
    "y = df['z_phot'].values[mask_cur]\n",
    "\n",
    "xmin, xmax = np.c_[x, y].min(), np.c_[x, y].max()\n",
    "dx, dy = 0.2, 0.35\n",
    "\n",
    "gridsize = (int((xmax-xmin)/dx), \n",
    "            int((xmax-xmin)/dy))\n",
    "\n",
    "fig, ax = plt.subplots(1, figsize=(3, 3), dpi=200)\n",
    "ax.set_xlabel('$z_{phot}$')\n",
    "ax.set_ylabel('$z_{spec}$')\n",
    "ax.set_xlim(0, 12.2)\n",
    "ax.set_ylim(0.0, 12.2)\n",
    "\n",
    "ax.hexbin(y, x, gridsize=gridsize,\n",
    "          extent=(xmin, xmax, xmin, xmax), mincnt=1,\n",
    "          edgecolors='none')\n",
    "ax.plot([xmin, xmax], [xmin, xmax], ls='--', c='r', lw=1.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load EAZY best-fit coefficients\n",
    "fpath = 'eazy-output/corr_sfhz_13/gds_jades_eazy.data.fits'\n",
    "with fits.open(fpath) as hdul:\n",
    "    coeffs = hdul['COEFFS'].data\n",
    "    print(hdul.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catalog paths\n",
    "cat_name = 'gds_jades_eazy'\n",
    "cat_path = f'./data/{cat_name}.fits'\n",
    "keys_id = ['ID id', 'RA ra', 'DEC dec', 'z_spec z_spec']\n",
    "\n",
    "# template paths\n",
    "\"\"\"templ_paths = [\"templates/sfhz/corr_sfhz_13.param\",\n",
    "               \"templates/sfhz/blue_sfhz_13.param\",\n",
    "               \"templates/templates-c2020/45k/fsps_45k.param\"]\"\"\"\n",
    "\"\"\"out_names = [f.split('/')[-1].split('.')[0] for f in templ_paths]\n",
    "out_paths = [f\"eazy-output/{f}\" for f in out_names]\"\"\"\n",
    "out_paths = [\"_\".join(p.split('_')[:-1]) + f\"_{runTime}\" for p in out_paths]\n",
    "paths = np.array([templ_paths, out_paths]).T\n",
    "\n",
    "# iterate over tempalte sets\n",
    "for tpath, opath in paths[:1]:\n",
    "    \n",
    "    params = {\"cat_path\": cat_path,\n",
    "              \"templ_path\": tpath,\n",
    "              \"out_path\": opath,\n",
    "              \"FIX_ZSPEC\": 'n',\n",
    "              \"USE_ZSPEC_FOR_REST\": 'n',\n",
    "              \"Z_MAX\": 12.0,\n",
    "              \"H0\": cosmo.H0,\n",
    "              \"OMEGA_M\": cosmo.Om0,\n",
    "              \"OMEGA_L\": cosmo.Ode0,\n",
    "              \"CATALOG_FORMAT\": 'fits',\n",
    "              'VERBOSE': 'n'}\n",
    "    \n",
    "    # write eazy config files\n",
    "    filt_num, fnames = ez.write_config(cat_name, filts, zps, keys_id,\n",
    "                                       out_path=opath, fwrite=False)\n",
    "    \n",
    "    # get a photoz object\n",
    "    with io.capture_output() as captured: # capture output\n",
    "        pz = ez.eazy_init_photoz(params, **fnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get best-fit redshifts and add to the catalog\n",
    "tab_zbest = Table.from_pandas(df[['ID', 'z_phot', 'z_phot_risk']])\n",
    "zbest = join(pz.cat[['ID']], tab_zbest, \n",
    "             keys='ID', join_type='left')\n",
    "\n",
    "# get best-fit templates at zbest\n",
    "#pz.fit_at_zbest(zbest=zbest)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from astropy.coordinates import SkyCoord\n",
    "\n",
    "def match_catalogs(samp_x, samp_y, cat_x, cat_y, max_sep=1.0*u.arcsec):\n",
    "    sample = SkyCoord(ra=samp_x*u.degree, dec=samp_y*u.degree)\n",
    "    catalog = SkyCoord(ra=cat_x*u.degree, dec=cat_y*u.degree)\n",
    "    idx, d2d, d3d = sample.match_to_catalog_sky(catalog)\n",
    "    samp_sel = d2d < max_sep\n",
    "    return samp_sel, idx\n",
    "\n",
    "#=== load meta data from spec files\n",
    "dname = \"hlsp_jades_jwst_nirspec_goods-s-deephst_clear-prism_v1.0\"\n",
    "fpath = os.path.join(os.getenv('astrodata'), 'gds/jades/spec', dname)\n",
    "\n",
    "fnames_1d = [f for f in os.listdir(fpath) if '_x1d.fits' in f]\n",
    "fpaths_1d = np.sort([os.path.join(fpath, f) for f in fnames_1d])\n",
    "\n",
    "# get RA and DEC from the 1D spectra headers\n",
    "df_spec = pd.DataFrame(columns=['ID', 'RA', 'DEC'], dtype=np.float32)\n",
    "spec_data = {}\n",
    "for f in fpaths_1d:\n",
    "    id_fname = int(f.split('/')[-1].split('-')[3].strip('_clear'))\n",
    "    with fits.open(f) as hdul:\n",
    "        hdr = hdul[0].header\n",
    "        row = np.array([id_fname, hdr['RA'], hdr['DEC']]).reshape(1, -1)\n",
    "        df_cur = pd.DataFrame(row, columns=['ID', 'RA', 'DEC'])\n",
    "        df_spec = pd.concat([df_spec, df_cur])\n",
    "        \n",
    "        \n",
    "        unit = u.Unit(hdr['BUNIT']) # erg/s/cm2/A\n",
    "        flux = hdul[1].data['FLUX'] * unit\n",
    "        fluxerr = hdul[1].data['FLUX_ERR'] * unit\n",
    "        wave = hdul[1].data['WAVELENGTH'] * u.um\n",
    "        equiv = u.spectral_density(wave.to(u.AA))\n",
    "        flux = flux.to(unit * u.AA / u.Hz, equivalencies=equiv)\n",
    "        fluxerr = fluxerr.to(unit * u.AA / u.Hz, equivalencies=equiv)\n",
    "        spec_data[id_fname] = [wave.value, \n",
    "                               flux.to(u.uJy).value, \n",
    "                               fluxerr.to(u.uJy).value]\n",
    "        #spec_data[id_fname] = hdul[1].data['FLUX']\n",
    "        \n",
    "\n",
    "df_spec.reset_index(drop=True, inplace=True)\n",
    "df_spec.ID = df_spec.ID.astype(np.int32)\n",
    "\n",
    "#===match catalogs\n",
    "\n",
    "# match spec sample to photo catalog\n",
    "cat_x = df['ra'].values\n",
    "cat_y = df['dec'].values\n",
    "samp_x = df_spec['RA'].values\n",
    "samp_y = df_spec['DEC'].values\n",
    "mask_samp, idx_cat = match_catalogs(samp_x, samp_y, cat_x, cat_y, \n",
    "                                    max_sep=0.8*u.arcsec)\n",
    "\n",
    "# add spec-flag column to catalog\n",
    "df['ID_spec'] = np.nan\n",
    "df.loc[idx_cat[mask_samp], 'ID_spec'] = df_spec.loc[mask_samp, 'ID'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#=== rebin spectrum\n",
    "\n",
    "from astropy import units as u\n",
    "\n",
    "#x = wave\n",
    "#y = flux_floor\n",
    "#ye = flux_floor_err\n",
    "\n",
    "def rebin_spec(x, y, ye, xlo=None, xhi=None, bw=1):\n",
    "    \"\"\" \n",
    "    Rebin the spectrum to get higher SN\n",
    "    \"\"\"\n",
    "    from spectres import spectres\n",
    "    x_new = np.arange(xlo+bw, xhi, bw)\n",
    "    y_new, ye_new = spectres(x_new, x, y, spec_errs=ye)\n",
    "    return x_new, y_new, ye_new\n",
    "\n",
    "def plot_binned_spec(x, y, ye, x_new, y_new, ye_new):\n",
    "    \n",
    "    axs = plt.figure(figsize=(5, 5), dpi=100).subplot_mosaic(\n",
    "        \"\"\"\n",
    "        a\n",
    "        b\n",
    "        c\n",
    "        \"\"\",\n",
    "        gridspec_kw={\n",
    "            \"height_ratios\": [3, 1, 1],\n",
    "            \"hspace\": 0.0\n",
    "        }\n",
    "    )\n",
    "\n",
    "    axs['a'].step(x, y, label='original') # original binning\n",
    "    axs['a'].step(x_new, y_new, label='rebinned') # original binning\n",
    "    axs['a'].set_ylabel('f')\n",
    "    axs['a'].set_ylim(0.0, 0.05)\n",
    "    axs['a'].set_xticklabels([])\n",
    "    axs['a'].legend()\n",
    "    axs['b'].step(x, y/ye)\n",
    "    axs['b'].step(x_new, y_new / ye_new)\n",
    "    axs['b'].set_ylabel('SNR')\n",
    "    axs['b'].set_ylim(0.0, 10)\n",
    "    axs['c'].step(x, ye)\n",
    "    axs['c'].step(x_new, ye_new)\n",
    "    axs['c'].set_ylabel('$\\Delta$f')\n",
    "    axs['c'].set_ylim(0.0, 0.05)\n",
    "\n",
    "    plt.show()\n",
    "    return \n",
    "\n",
    "#spaxel_lam_orig = (wave.max() - wave.min()) / 1024\n",
    "#spaxel_lam_rbin = (wave.max() - wave.min()) / 1024 * bw\n",
    "#print(f\"original spectrum: 1 spaxel = {spaxel_lam_orig:.2f} A\")\n",
    "#print(f\"rebinned spectrum: 1 spaxel = {spaxel_lam_rbin:.2f} A, bw={bw:.1f} A\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = spec_data[2651][0]\n",
    "y = spec_data[2651][1]\n",
    "ye = spec_data[2651][2]\n",
    "xbin, ybin, yebin = rebin_spec(x, y, ye, xlo=x.min(), xhi=x.max(), bw=0.01)\n",
    "plot_binned_spec(x, y, ye, xbin, ybin, yebin)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def obs2local(wave, flux, fluxerr, z, zerr=0):\n",
    "    \"\"\"\n",
    "    Convert observed-frame fluxes to rest-frame\n",
    "    \"\"\"\n",
    "    wave, flux, fluxerr = np.array(wave), np.array(flux), np.array(fluxerr)\n",
    "    wave_rest = wave / (1 + z)\n",
    "    #flux_rest = flux * (1 + z)\n",
    "    #fluxerr_rest = np.sqrt((fluxerr * (1 + z))**2 + (flux * zerr)**2)\n",
    "    return wave_rest, flux, fluxerr\n",
    "    return wave_rest, flux_rest, fluxerr_rest\n",
    "\n",
    "from scipy.interpolate import interp1d\n",
    "\n",
    "def scale2MinimizeChi2(func1,func2):#! not tested\n",
    "    \"\"\"\n",
    "    Scale func2 to minimize chi2 between func1 and func2\n",
    "    \"\"\"\n",
    "    #from solve algebra, one can find that the solution is given by:\n",
    "    #Sum{func1*func2}=scale*Sum{func2*func2}\n",
    "    #scale=Sum{func1*func2}/Sum{func2*func2}\n",
    "    \n",
    "    func1_xs = func1[0]\n",
    "    func1_ys = func1[1]\n",
    "    func2_xs = func2[0]\n",
    "    func2_ys = func2[1]\n",
    "\n",
    "    #remove nans in func1\n",
    "    notNanMask = np.invert(np.isnan(func1_ys))\n",
    "    func1_xs = func1_xs[notNanMask]\n",
    "    func1_ys = func1_ys[notNanMask]\n",
    "\n",
    "    #remove nans in func2\n",
    "    notNanMask = np.invert(np.isnan(func2_ys))\n",
    "    func2_xs = func2_xs[notNanMask]\n",
    "    func2_ys = func2_ys[notNanMask]\n",
    "\n",
    "    #cut func2 to the same range as func1\n",
    "    mask = (func2_xs>=func1_xs.min())&(func2_xs<=func1_xs.max())\n",
    "    func2_xs = func2_xs[mask]\n",
    "    func2_ys = func2_ys[mask]\n",
    "\n",
    "    #cut func1 to the same range as func2\n",
    "    mask = (func1_xs>=func2_xs.min())&(func1_xs<=func2_xs.max())\n",
    "    func1_xs = func1_xs[mask]\n",
    "    func1_ys = func1_ys[mask]\n",
    "\n",
    "    #append ends to func1 and func2 with same x\n",
    "    if func1_xs.min()<func2_xs.min():\n",
    "        func2_xs = np.array([func1_xs.min()]+list(func2_xs))\n",
    "        func2_ys = np.array([func2_ys[0]]+list(func2_ys))\n",
    "    elif func2_xs.min()<func1_xs.min():\n",
    "        func1_xs = np.array([func2_xs.min()]+list(func1_xs))\n",
    "        func1_ys = np.array([func1_ys[0]]+list(func1_ys))\n",
    "    if func1_xs.max()>func2_xs.max():\n",
    "        func2_xs = np.array(list(func2_xs)+[func1_xs.max()])\n",
    "        func2_ys = np.array(list(func2_ys)+[func2_ys[-1]])\n",
    "    elif func2_xs.max()>func1_xs.max():\n",
    "        func1_xs = np.array(list(func1_xs)+[func2_xs.max()])\n",
    "        func1_ys = np.array(list(func1_ys)+[func1_ys[-1]])\n",
    "\n",
    "    #use interpolation to find values of func2 at func1_xs and vice versa\n",
    "    def interpolate(x,y,xs):\n",
    "        f = interp1d(x,y)\n",
    "        return f(xs)\n",
    "    func1_ys_at_func2_xs = interpolate(func1_xs,func1_ys,func2_xs)\n",
    "    func2_ys_at_func1_xs = interpolate(func2_xs,func2_ys,func1_xs)\n",
    "    #interweve the interpolations to create new functions\n",
    "    X = np.concatenate((func1_xs,func2_xs))\n",
    "    order = np.argsort(X)\n",
    "    X = X[order]\n",
    "    Y_func1 = np.concatenate((func1_ys,func1_ys_at_func2_xs))\n",
    "    Y_func2 = np.concatenate((func2_ys_at_func1_xs,func2_ys))\n",
    "    Y_func1 = Y_func1[order]\n",
    "    Y_func2 = Y_func2[order]\n",
    "\n",
    "    #calculate sums\n",
    "    sum_func1_func2 = np.sum(Y_func1*Y_func2)\n",
    "    sum_func2_func2 = np.sum(Y_func2*Y_func2)\n",
    "\n",
    "    #calculate scale\n",
    "    scale = sum_func1_func2/sum_func2_func2\n",
    "\n",
    "    #return scale\n",
    "    return scale "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "doObsPlot = True\n",
    "doLocPlot = True   \n",
    "\n",
    "# get spec for current obj\n",
    "print(\"Objects: \" , spec_data.keys())\n",
    "#objids = [2651, 3968, 7507]\n",
    "objids = list(spec_data.keys())\n",
    "#get z_phoy_chi2 from df\n",
    "z_phot_chi2 = df['z_phot_chi2'][df['ID_spec'].isin(objids)].values\n",
    "#sort objids by z_phot_chi2\n",
    "chi2_sort = np.argsort(z_phot_chi2)[::-1]\n",
    "objids = np.array(objids)[chi2_sort]\n",
    "objids = objids[:200]\n",
    "for i,objid in enumerate(objids):\n",
    "    x = spec_data[objid][0]\n",
    "    y = spec_data[objid][1]\n",
    "    ye = spec_data[objid][2]\n",
    "    xbin, ybin, yebin = x, y, ye\n",
    "    #rebin every n points by average\n",
    "    n = 1#4\n",
    "    xbin = np.array([np.mean(xbin[i:i+n]) for i in range(0, len(xbin), n)])\n",
    "    ybin = np.array([np.mean(ybin[i:i+n]) for i in range(0, len(ybin), n)])\n",
    "    yebin = np.array([np.sqrt(sum(yebin[i:i+n]**2)) for i in range(0, len(yebin), n)])\n",
    "\n",
    "    #xbin, ybin, yebin = rebin_spec(x, y, ye, xlo=x.min(), xhi=x.max(), bw=0.005)\n",
    "    id_cat = df['ID'][df['ID_spec'].isin([objid])].values\n",
    "\n",
    "    # get cur obj id and z\n",
    "    idx_cat = np.isin(zbest['ID'].data, id_cat)\n",
    "    try:\n",
    "        z_phot = zbest['z_phot'][idx_cat][0]\n",
    "        z_phot_e = zbest['z_phot_risk'][idx_cat][0]#!not sure if this is the right error\n",
    "        z_spec = df['z_spec'][df['ID_spec'].isin([objid])].values[0]\n",
    "    except:\n",
    "        continue\n",
    "    chi2_fit = z_phot_chi2[chi2_sort][i]\n",
    "    \"\"\"if abs(z_phot - z_spec) < 0.1 or np.isnan(z_spec):\n",
    "        continue\"\"\"\n",
    "    \"\"\"if abs(z_spec/z_phot) > 0.9 or abs(z_spec/z_phot) < 0.7 or z_spec < 5:\n",
    "        continue\"\"\"\n",
    "    if z_spec < 8 or (abs(z_spec/z_phot) > 0.96 and abs(z_spec/z_phot) < 1.04):\n",
    "        continue\n",
    "\n",
    "\n",
    "    #=== plot the data\n",
    "    if doObsPlot:\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(16, 7), dpi=300)\n",
    "        axs = axs.flatten()\n",
    "        axs[0].set_xlabel(r'$\\lambda_{\\rm obs}~[{\\rm \\mu m}]$')\n",
    "        axs[0].set_ylabel(r'$f_{\\nu}~{\\rm [\\mu Jy]}$')\n",
    "        #ax.set_xlim(0.2, 6.0)\n",
    "        #ax.set_ylim(-0.001, 0.01)\n",
    "\n",
    "        fig, data = pz.show_fit(id=id_cat, add_label=True, axes=axs,\n",
    "                                show_components=True,\n",
    "                                zshow=z_phot,\n",
    "                                xlim=[0.1, 10.0], \n",
    "                                showpz=True, logpz=True, zr=[0, 12],\n",
    "                                show_missing=True,\n",
    "                                show_stars=False, snr_thresh=1.0,\n",
    "                                show_fnu=True)#maglim=[])\n",
    "\n",
    "        axs[0].set_xlim(0.25, 5)\n",
    "        axs[0].set_ylim(0.000, np.mean(ybin[np.invert(np.isnan(ybin))])*0.7)\n",
    "\n",
    "        axs[0].step(xbin, ybin/4, label='rebinned', lw=1, alpha=0.3, c='k')\n",
    "        xbinWidth = (max(xbin) - min(xbin)) / len(xbin)\n",
    "        axs[0].scatter((xbin[1:] + xbin[:-1])/2, ybin[1:]/4, s=2.0, color='r', lw=0.5)\n",
    "        #ax.errorbar((xbin[1:] + xbin[:-1])/2, ybin[1:]/4, yerr=yebin[1:]/4, fmt='none', ecolor='r', lw=0.5, capsize=0.7, capthick=0.3, alpha=0.2)\n",
    "\n",
    "        axs[0].annotate(rf\"$z_{{spec}}={z_spec:.2f}$\", xy=(0.80, 0.08), \n",
    "                    xycoords='axes fraction')\n",
    "        axs[0].annotate(rf\"$z_{{phot}}={z_phot:.2f}$\", xy=(0.80, 0.02),\n",
    "                    xycoords='axes fraction')\n",
    "        axs[0].annotate(rf\"$\\chi^2={chi2_fit:.1f}$\", xy=(0.80, 0.14),\n",
    "                    xycoords='axes fraction')\n",
    "        axs[0].legend(loc='upper left', bbox_to_anchor=(0.0, 1.0), fontsize=8)\n",
    "        axs[0].set_title(f'ID: {id_cat[0]}')\n",
    "        \n",
    "        axs[1].set_xlabel('z')\n",
    "        axs[1].set_ylabel('p(z)')\n",
    "        axs[1].set_yscale('log')\n",
    "        axs[1].set_ylim(1e-2, 1.3e0)\n",
    "\n",
    "        plt.show()\n",
    "\n",
    "    #do a simular plot but restframe\n",
    "    if doLocPlot:\n",
    "        fig, axs = plt.subplots(1, 2, figsize=(16, 7), dpi=300)\n",
    "        axs = axs.flatten()\n",
    "        axs[0].set_xlabel(r'$\\lambda_{\\rm rest}~[{\\rm \\mu m}]$')\n",
    "        axs[0].set_ylabel(r'$f_{\\nu}~{\\rm [\\mu Jy]}$')\n",
    "        #ax.set_xlim(0.2, 6.0)\n",
    "        #ax.set_ylim(-0.001, 0.01)\n",
    "\n",
    "        fig, data = pz.show_fit(id=id_cat, add_label=True, axes=axs,\n",
    "                                show_components=False,\n",
    "                                zshow=z_phot,\n",
    "                                xlim=[0.1, 10.0], \n",
    "                                showpz=True, logpz=True, zr=[0, 12],\n",
    "                                show_missing=True,\n",
    "                                show_stars=False, snr_thresh=1.0,\n",
    "                                show_fnu=True)#maglim=[])\n",
    "\n",
    "        #get xy data from plot lines and convert to restframe\n",
    "        x_fit = copy(axs[0].lines[3].get_xdata())#fit\n",
    "        y_fit = copy(axs[0].lines[3].get_ydata())\n",
    "        x_photpoints = copy(axs[0].lines[1].get_xdata())#black points\n",
    "        y_photpoints = copy(axs[0].lines[1].get_ydata())\n",
    "        x_fitpoints_w = copy(axs[0].collections[0].get_offsets()[:,0])#white points (under blue points)\n",
    "        y_fitpoints_w = copy(axs[0].collections[0].get_offsets()[:,1])\n",
    "        x_fitpoints = copy(axs[0].collections[1].get_offsets()[:,0])#blue points\n",
    "        y_fitpoints = copy(axs[0].collections[1].get_offsets()[:,1])\n",
    "\n",
    "\n",
    "        x_photpoints_rest, y_photpoints_rest, ye_points_rest = obs2local(x_photpoints, y_photpoints, y_photpoints*0, z_spec)#scaling of the black points\n",
    "        x_fitpoints_w_rest, y_fitpoints_w_rest, ye_fitpoints_w_rest = obs2local(x_fitpoints_w, y_fitpoints_w, y_fitpoints_w*0, z_phot)#scaling of the white points\n",
    "        x_fitpoints_rest, y_fitpoints_rest, ye_fitpoints_rest = obs2local(x_fitpoints, y_fitpoints, y_fitpoints*0, z_phot)#scaling of the blue points\n",
    "        x_fit_rest, y_fit_rest, _ = obs2local(x_fit, y_fit, y_fit*0, z_phot)#scaling of the blue fit\n",
    "        xbin, ybin, yebin = obs2local(xbin, ybin, yebin, z_spec)#scaling of the red points\n",
    "\n",
    "        #plot y_fit_rest to match in amplitude at x=0.55\n",
    "        scaling = ybin[np.argmin(np.abs(xbin-0.6))]/4/y_fit_rest[np.argmin(np.abs(x_fit_rest-0.6))]\n",
    "        if scaling<0:\n",
    "            print(\"Negative scaling!, fixing...\")\n",
    "            scaling = 1\n",
    "        y_fit_dumbscaling = copy(y_fit_rest)*scaling\n",
    "        axs[0].plot(x_fit_rest, y_fit_dumbscaling, c='y', lw=1, alpha=0.3, label='visual scaling')\n",
    "\n",
    "        try:\n",
    "            scaling = scale2MinimizeChi2([xbin, ybin], [x_fit_rest, y_fit_rest])\n",
    "        except:\n",
    "            plt.show()\n",
    "            continue\n",
    "        y_fit_rest *= scaling\n",
    "        y_fitpoints_rest *= scaling\n",
    "        y_fitpoints_w_rest *= scaling\n",
    "\n",
    "        #rebin the blue fit to the xbins\n",
    "        y_fit_rest_rebinned = np.array([np.mean(y_fit_rest[np.logical_and(x_fit_rest>=xbin[i], x_fit_rest<xbin[i+1])]) for i in range(len(xbin)-1)])\n",
    "        x_fit_rest_rebinned = np.array([(xbin[i]+xbin[i+1])/2 for i in range(len(xbin)-1)])\n",
    "        axs[0].plot(x_fit_rest_rebinned, y_fit_rest_rebinned, c='g', lw=3, alpha=0.2, label='rebinned fit')\n",
    "\n",
    "        axs[0].lines[3].set_xdata(x_fit_rest)\n",
    "        axs[0].lines[3].set_ydata(y_fit_rest)\n",
    "        axs[0].lines[1].set_xdata(x_photpoints_rest)\n",
    "        axs[0].lines[1].set_ydata(y_photpoints_rest)\n",
    "        axs[0].collections[0].set_offsets(np.c_[x_fitpoints_w_rest, y_fitpoints_w_rest])\n",
    "        #axs[0].collections[0].set_sizes(np.ones(len(x_fitpoints_rest))*10)\n",
    "        axs[0].collections[1].set_offsets(np.c_[x_fitpoints_rest, y_fitpoints_rest])\n",
    "        #axs[0].collections[0].set_sizes(np.ones(len(x_fitpoints_rest))*10)\n",
    "\n",
    "        #set label for fit to r'least $\\Chi^2$ scaling'\n",
    "        axs[0].lines[3].set_label(r'least $\\chi^2$ scaling')\n",
    "        \n",
    "        axs[0].set_xlim(*obs2local([0.25, 10], [0, 0], [0, 0], z_spec)[0])\n",
    "        axs[0].set_xlim([axs[0].get_xlim()[0], max(xbin)])\n",
    "        #set minimum of y to minimum in array under 1.5 micron\n",
    "        ybin_inLim = ybin[np.invert(np.isnan(ybin))][xbin[np.invert(np.isnan(ybin))]<1.5]\n",
    "        axs[0].set_ylim(\n",
    "            min(0,min(ybin_inLim)/8),\n",
    "            np.mean(ybin[np.invert(np.isnan(ybin))])*0.7+(1+np.std(ybin[np.invert(np.isnan(ybin))]))*0.01\n",
    "            )\n",
    "\n",
    "        axs[0].step(xbin, ybin/4, label='rebinned', lw=1, alpha=0.3, c='k')\n",
    "        xbinWidth = (max(xbin) - min(xbin)) / len(xbin)\n",
    "        axs[0].scatter((xbin[1:] + xbin[:-1])/2, ybin[1:]/4, s=2.0, color='r', lw=0.5)\n",
    "        #ax.errorbar((xbin[1:] + xbin[:-1])/2, ybin[1:]/4, yerr=yebin[1:]/4, fmt='none', ecolor='r', lw=0.5, capsize=0.7, capthick=0.3, alpha=0.2)\n",
    "\n",
    "        axs[0].annotate(rf\"$z_{{spec}}={z_spec:.2f}$\", xy=(0.80, 0.08),\n",
    "                    xycoords='axes fraction')\n",
    "        axs[0].annotate(rf\"$z_{{phot}}={z_phot:.2f}$\", xy=(0.80, 0.02),\n",
    "                    xycoords='axes fraction')\n",
    "        axs[0].annotate(rf\"$\\chi^2={chi2_fit:.1f}$\", xy=(0.80, 0.14),\n",
    "                    xycoords='axes fraction')\n",
    "        axs[0].legend(loc='upper left', bbox_to_anchor=(0.0, 1.0), fontsize=8)\n",
    "        axs[0].set_title(f'ID: {id_cat[0]}')\n",
    "\n",
    "        axs[1].set_xlabel('z')\n",
    "        axs[1].set_ylabel('p(z)')\n",
    "        axs[1].set_yscale('log')\n",
    "        axs[1].set_ylim(1e-2, 1.3e0)\n",
    "\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "mosTiling = 3\n",
    "mosaicLen = ceil(len(ftempl_strs) / mosTiling)\n",
    "figMos, axsMos = plt.subplots(mosTiling, mosaicLen, figsize=(mosTiling*mosaicLen*1.5, 3*mosTiling), dpi=200)\n",
    "#transpose and flatten\n",
    "axsMos = axsMos.T\n",
    "axsMos = axsMos.flatten()\n",
    "\n",
    "for i, ftempl in enumerate(ftempl_strs):\n",
    "\n",
    "    outpath = outpaths.format(ftempl=ftempl, runTime=runTime)\n",
    "    tbl = Table.read(outpath)\n",
    "    names = [name for name in tbl.colnames if len(tbl[name].shape) <= 1]\n",
    "    df_props = tbl[names].to_pandas()\n",
    "\n",
    "    #find light intensities\n",
    "    ids = df_props['id'].values\n",
    "    filtTab = Table.read(inpath, hdu=4)\n",
    "    #get values ending with \"CIRC1\"\n",
    "    pointIDs = filtTab['ID']\n",
    "    filtTab = filtTab[[f for f in filtTab.colnames if f.endswith('CIRC1')]]\n",
    "    #get dictionary version of table\n",
    "    filtTab = filtTab.to_pandas()\n",
    "    keys = filtTab.keys()\n",
    "    fluxes = np.array([np.array(filtTab[key]) for key in keys]).T\n",
    "    pointIntensities = np.sum(fluxes, axis=1)\n",
    "\n",
    "    #clear up bad ids and make simular sort\n",
    "    for j,id in list(enumerate(ids))[::-1]:\n",
    "        if id not in df_props['id'].values:\n",
    "            pointIntensities = np.delete(pointIntensities, j)\n",
    "            ids = np.delete(ids, j)\n",
    "    #sort pointIntensities and ids to match df_props\n",
    "    pointIntensities = pointIntensities[np.argsort(ids)]\n",
    "    ids = np.sort(ids)\n",
    "    antiSort = np.argsort(df_props['id'].values)\n",
    "    sort = np.argsort(antiSort)\n",
    "    pointIntensities = pointIntensities[sort]\n",
    "    ids = ids[sort]\n",
    "\n",
    "    mask_cur = (df_props['z_spec'] > 0) & (~df_props['z_phot'].isna())\n",
    "    x = df_props['z_spec']\n",
    "    y = df_props['z_phot']\n",
    "    above = y > x + (1 + x) * 0.15 # outliers\n",
    "    below = y < x - (1 + x) * 0.15\n",
    "    outlier = above | below\n",
    "    mask_in = mask_cur & (~outlier)\n",
    "    x = x.values[mask_cur]\n",
    "    y = y.values[mask_cur]\n",
    "    #mask_out = mask_cur & outlier\n",
    "    chi2_fit = df_props['z_phot_chi2'].values[mask_cur]/len(filtTab.keys())#!new\n",
    "    avgchi2_fit = np.mean(chi2_fit)\n",
    "    medchi2_fit = np.median(chi2_fit)\n",
    "    \n",
    "    avgchi2_fit_in = df_props['z_phot_chi2'].values[mask_in]/len(x)#!new\n",
    "    c = np.log10(pointIntensities[mask_cur])*((x/(1+x))**2)#!quilitative reshift scaling\n",
    "\n",
    "    #calculate chi2 with linear regression of x and y\n",
    "    chi2 = np.sum((y - x)**2/1)/len(x)#/len(x)#!dunno what to put for sigma\n",
    "\n",
    "    xmin, xmax = np.c_[[x, y]].min(), np.c_[[x, y]].max()\n",
    "\n",
    "    #ax.hexbin(x1, x2, gridsize=100, cmap='Greys', bins='log',\n",
    "    #          mincnt=1, edgecolors='none', \n",
    "    #          extent=[xmin, xmax, xmin, xmax])\n",
    "    axsMos[i].scatter(x, y, s=2.0, c=c, cmap='Greys')\n",
    "    axsMos[i].plot([xmin, xmax], [xmin, xmax], c='k', ls='--', lw=0.5)\n",
    "    \n",
    "    dict_stat = hmod.phot_spec_zs_stats(y, x)\n",
    "\n",
    "    #annotate in bottom right\n",
    "    annotAnchor = np.array((1.025, 0.6))\n",
    "    axsMos[i].set_title(f'{ftempl}', fontsize=10)\n",
    "    ay = 0\n",
    "    for j, (k, val) in enumerate(dict_stat.items()):\n",
    "        if k == 'eta': tex = '\\\\'\n",
    "        else: tex = ''\n",
    "        axsMos[i].annotate(rf'${tex}{k}$: {val:.3f}', annotAnchor - np.array((0.05, (ay:=ay+0.06))),\n",
    "                            xycoords='axes fraction', fontsize=8, ha='right')\n",
    "    axsMos[i].annotate(r\"$\\overline{\\chi' ^2_{fit}}$\" + f': {avgchi2_fit:.1f}', annotAnchor - np.array((0.05, (ay:=ay+0.085))),\n",
    "                        xycoords='axes fraction', fontsize=8, ha='right')\n",
    "    axsMos[i].annotate(r\"$\\widetilde{\\chi' ^2_{fit}}$\" + f': {medchi2_fit:.1f}', annotAnchor - np.array((0.05, (ay:=ay+0.085))),\n",
    "                        xycoords='axes fraction', fontsize=8, ha='right')\n",
    "    axsMos[i].annotate(r\"$\\chi' ^2_z$\" + f': {chi2:.1f}', annotAnchor - np.array((0.05, (ay:=ay+0.085))),\n",
    "                        xycoords='axes fraction', fontsize=8, ha='right')\n",
    "    axsMos[i].annotate(r\"$\\overline{\\chi' ^2_{fit\\_in}}$\" + f': {np.mean(avgchi2_fit_in):.1f}', annotAnchor - np.array((0.05, (ay:=ay+0.085))),\n",
    "                        xycoords='axes fraction', fontsize=8, ha='right')\n",
    "\n",
    "\n",
    "    axsMos[i].set_xlim(0,14*1.5)\n",
    "    axsMos[i].set_ylim(0,14)\n",
    "\n",
    "    #set same ticks on x as y\n",
    "    axsMos[i].set_xticks(axsMos[i].get_yticks()[:-1])\n",
    "\n",
    "if len(ftempl_strs) % 3 != 0:\n",
    "    axsMos[-1].axis('off')\n",
    "if len(ftempl_strs) % 3 == 1:\n",
    "    axsMos[-2].axis('off')\n",
    "\n",
    "#axis label\n",
    "figMos.text(0.5, 0.05, '$z_{spec}$', ha='center', va='center')\n",
    "figMos.text(0.05, 0.5, '$z_{phot}$', ha='center', va='center', rotation='vertical')\n",
    "\n",
    "figMos.savefig('./docs/figures/zs_mosaic.png', dpi=200, bbox_inches='tight')\n",
    "figMos.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tab = Table.read(f'eazy-output/fsps_60k_{runTime}/gds_jades_eazy.zout.fits')\n",
    "#diff = np.abs(tab['z_spec'].data - tab['z_phot'].data) / tab['z_spec'].data\n",
    "diff = np.abs(tab['z_spec'].data / tab['z_phot'].data)\n",
    "plt.hist(diff, bins=100, range=[0,1.2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# catalog paths\n",
    "cat_name = 'gds_jades_eazy'\n",
    "cat_path = f'./data/{cat_name}.fits'\n",
    "keys_id = ['ID id', 'RA ra', 'DEC dec', 'z_spec z_spec']\n",
    "\n",
    "# template paths\n",
    "out_names = [\".\".join(f.split('/')[-1].split('.')[:-1]) for f in templ_paths]\n",
    "out_paths = [f\"eazy-output/{f}_{runTime}\" for f in out_names]\n",
    "paths = np.array(out_paths)\n",
    "\n",
    "# iterate over tempalte sets\n",
    "masses = {}\n",
    "for i, opath in enumerate(out_paths):\n",
    "    fn = out_names[i]\n",
    "    fname = f\"{cat_name}.zout.fits\"\n",
    "    fpath = os.path.join(opath, fname)\n",
    "    mass = np.log10(Table.read(fpath)['mass'].data)\n",
    "    masses[fn] = mass"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "eazy39",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
